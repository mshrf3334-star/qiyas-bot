# app.py â€” Qiyas Bot (Webhook/PTB v21) â€” Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù…Ù„ÙØ§Øª data
# ----------------------------------------------------------
import os, logging, random, re, asyncio
from collections import deque
from typing import List, Dict, Any, Optional, Tuple

from telegram import (
    Update, KeyboardButton, ReplyKeyboardMarkup,
    InlineKeyboardButton, InlineKeyboardMarkup
)
from telegram.constants import ChatAction
from telegram.ext import (
    Application, CommandHandler, MessageHandler,
    CallbackQueryHandler, ContextTypes, filters
)

# ================= Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© =================
BOT_TOKEN   = os.environ.get("TELEGRAM_BOT_TOKEN")
WEBHOOK_URL = (os.environ.get("WEBHOOK_URL") or "").rstrip("/")
PORT        = int(os.environ.get("PORT", "10000"))

# Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
AI_API_KEY   = os.environ.get("AI_API_KEY")
AI_MODEL     = os.environ.get("AI_MODEL", "gpt-4o-mini")
AI_BASE_URL  = os.environ.get("AI_BASE_URL")  # Ø§Ø®ØªÙŠØ§Ø±ÙŠ (Ø¨ÙˆØ§Ø¨Ø§Øª OpenRouter ÙˆÙ†Ø­ÙˆÙ‡Ø§)

if not BOT_TOKEN:
    raise RuntimeError("TELEGRAM_BOT_TOKEN Ù…ÙÙ‚ÙˆØ¯")
if not WEBHOOK_URL:
    raise RuntimeError("WEBHOOK_URL Ù…ÙÙ‚ÙˆØ¯ (Ù…Ø«Ø§Ù„: https://your-app.onrender.com)")

# ===== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ =====
AI_MAX_TOKENS          = int(os.environ.get("AI_MAX_TOKENS", "650"))
AI_TEMPERATURE_DEFAULT = float(os.environ.get("AI_TEMPERATURE", "0.4"))
AI_STYLE_DEFAULT       = os.environ.get("AI_STYLE", "concise")  # concise | detailed

def get_ai_prefs(context):
    prefs = context.user_data.setdefault("ai_prefs", {})
    prefs.setdefault("model", os.environ.get("AI_MODEL", AI_MODEL))
    prefs.setdefault("temperature", AI_TEMPERATURE_DEFAULT)
    prefs.setdefault("style", AI_STYLE_DEFAULT)
    return prefs

def ai_system_prompt(style: str, ei_enabled: bool) -> str:
    tone = "Ù„Ø·ÙŠÙ ÙˆÙ…Ø·Ù…Ø¦Ù†" if ei_enabled else "Ø­ÙŠØ§Ø¯ÙŠ ÙˆÙ…Ø¨Ø§Ø´Ø±"
    depth = "Ù†Ù‚Ø§Ø· Ù…Ø®ØªØµØ±Ø© Ù…Ø¹ Ø®Ø·ÙˆØ§Øª Ù…Ø±Ù‚Ù…Ø©" if style == "concise" else "ØªÙØµÙŠÙ„ ÙˆØ§Ø¶Ø­ Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© Ù‚ØµÙŠØ±Ø© ÙˆØ®Ø·ÙˆØ§Øª Ø¯Ù‚ÙŠÙ‚Ø©"
    encouragement = "Ø§Ø®ØªÙ… Ø¨Ø¬Ù…Ù„Ø© ØªØ´Ø¬ÙŠØ¹ÙŠØ© Ù‚ØµÙŠØ±Ø©." if ei_enabled else "Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ø¥ÙŠØ¬Ø§Ø² Ø§Ù„Ù…Ù‡Ù†ÙŠ."
    return (
        "Ø£Ù†Øª Ù…Ø¯Ø±Ù‘Ø³ Ù‚Ø¯Ø±Ø§Øª (Ù‚ÙŠØ§Ø³) Ø®Ø¨ÙŠØ± Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. "
        f"Ø§ÙƒØªØ¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ {tone}. Ù‚Ø¯Ù‘Ù… {depth}. "
        "Ù‚Ø³Ù‘Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¥Ù„Ù‰ ÙÙ‚Ø±Ø§Øª Ø¨Ø¹Ù†ÙˆØ§Ù†Ø§Øª Ù‚ØµÙŠØ±Ø© ÙˆÙ†Ù‚Ø§Ø·. "
        "Ø§Ø±Ø¨Ø· Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¨Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù‚Ø¯Ø±Ø§Øª (ÙƒÙ…ÙŠ/Ù„ÙØ¸ÙŠ) Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©. "
        "ØªØ¬Ù†Ù‘Ø¨ Ø§Ù„Ø­Ø´ÙˆØŒ ÙˆØ§Ø°ÙƒØ± Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¨Ø§Ù‚ØªØ¶Ø§Ø¨. "
        f"{encouragement}"
    )

# ================= Ù„ÙˆÙ‚ =================
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s | %(levelname)s | %(name)s | %(message)s"
)
logging.getLogger("httpx").setLevel(logging.WARNING)
log = logging.getLogger("qiyas-bot")

# ======================================================
#                 Ø°ÙƒØ§Ø¡ Ø¹Ø§Ø·ÙÙŠ (Ù…Ø´Ø¬Ù‘Ø¹)
# ======================================================
EI_DEFAULT = True
def get_ei(context): 
    return context.user_data.get("ei", EI_DEFAULT)
def set_ei(context, value: bool): 
    context.user_data["ei"] = bool(value)

def ei_msg_correct(streak: int) -> str:
    msgs = ["ğŸ‘ Ù…Ù…ØªØ§Ø²! Ø«Ø¨Ù‘Øª Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙˆÙ‰.", "ğŸ”¥ Ø£Ø¯Ø§Ø¡ Ø¬Ù…ÙŠÙ„! Ø§Ø³ØªÙ…Ø±.", "âœ… Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙˆÙÙ‚Ø© â€” ÙƒÙÙˆ.", "ğŸŒŸ Ø£Ø­Ø³Ù†Øª! ØªØ±ÙƒÙŠØ²Ùƒ ÙˆØ§Ø¶Ø­."]
    bonus = f"\nØ³Ù„Ø³Ù„Ø© ØµØ­ÙŠØ­Ø© Ù…ØªØªØ§Ù„ÙŠØ©: {streak} âœ”ï¸" if streak >= 3 else ""
    return random.choice(msgs) + bonus

def ei_msg_wrong(explain: Optional[str]) -> str:
    soft = ["ÙˆÙ„Ø§ ÙŠÙ‡Ù…Ù‘ÙƒØŒ Ø¬Ø±Ù‘Ø¨ Ø§Ù„Ù„ÙŠ Ø¨Ø¹Ø¯Ù‡ Ø¨Ù‡Ø¯ÙˆØ¡.", "ğŸ‘ Ø®Ø°Ù‡Ø§ Ø®Ø·ÙˆØ© Ø®Ø·ÙˆØ©ØŒ ØªØ±ÙƒÙŠØ²Ùƒ Ø£Ù‡Ù….", "ğŸ’¡ Ø±Ø§Ø¬Ø¹ Ø§Ù„ÙÙƒØ±Ø© Ø¨Ù‡Ø¯ÙˆØ¡ ÙˆØ³ØªØªØ¶Ø­."]
    tip = f"\nØ§Ù„Ø´Ø±Ø­: {explain}" if explain else ""
    return random.choice(soft) + tip

# ======================================================
#          Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± (Ø°Ø§ÙƒØ±Ø© Ù‚ØµÙŠØ±Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¬Ù„Ø³Ø©)
# ======================================================
SEEN_LIMIT = 400
def seen_push(context, cat: str, key: str):
    deq: deque = context.user_data.setdefault(f"seen_{cat}", deque(maxlen=SEEN_LIMIT))
    deq.append(key)

def seen_has(context, cat: str, key: str) -> bool:
    deq: deque = context.user_data.setdefault(f"seen_{cat}", deque(maxlen=SEEN_LIMIT))
    return key in deq

# ======================================================
#                 Ù…ÙˆÙ„Ù‘ÙØ¯Ø§Øª Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
# ======================================================
def _choice4(correct: int | str, near: List[int | str]) -> Tuple[List[str], int]:
    opts: List[str] = []
    seen = set()
    def push(x):
        sx = str(x)
        if sx not in seen and len(opts) < 4:
            opts.append(sx)
            seen.add(sx)
    push(correct)
    for x in near:
        push(x)
    while len(opts) < 4:
        v = random.randint(-50, 200)
        push(v)
    random.shuffle(opts)
    return opts, opts.index(str(correct))

# ---- ÙƒÙ…ÙŠ ----
def gen_quant() -> Dict[str, Any]:
    t = random.choice(["arith", "linear", "percent", "pow", "mix"])
    if t == "arith":
        a, b = random.randint(-20, 90), random.randint(-20, 90)
        op = random.choice(["+", "-", "Ã—", "Ã·"])
        if op == "+":
            val = a + b
            opts, ans = _choice4(val, [val + random.choice([-3, -2, -1, 1, 2, 3]), val + 10, val - 10])
            q = f"Ø§Ø­Ø³Ø¨: {a} + {b} = ØŸ"
        elif op == "-":
            val = a - b
            opts, ans = _choice4(val, [val + random.choice([-3, -1, 1, 3]), val + 7, val - 7])
            q = f"Ø§Ø­Ø³Ø¨: {a} - {b} = ØŸ"
        elif op == "Ã—":
            a, b = random.randint(2, 20), random.randint(2, 15)
            val = a * b
            opts, ans = _choice4(val, [val + a, val - b, val + 10])
            q = f"Ø§Ø­Ø³Ø¨: {a} Ã— {b} = ØŸ"
        else:
            b = random.randint(2, 12)
            val = random.randint(2, 12)
            a = b * val
            opts, ans = _choice4(val, [val + 1, val - 1, val + 2])
            q = f"Ø§Ø­Ø³Ø¨: {a} Ã· {b} = ØŸ"
        return {"question": q, "options": opts, "answer_index": ans, "explain": "Ø¹Ù…Ù„ÙŠØ§Øª Ø­Ø³Ø§Ø¨ÙŠØ© Ø£Ø³Ø§Ø³ÙŠØ©."}

    if t == "linear":
        a = random.randint(2, 9)
        x = random.randint(-10, 12)
        b = random.randint(-10, 12)
        c = a * x + b
        q = f"Ø¥Ø°Ø§ ÙƒØ§Ù† {a}Ø³ + {b} = {c}ØŒ ÙÙ…Ø§ Ù‚ÙŠÙ…Ø© Ø³ØŸ"
        opts, ans = _choice4(x, [x + 1, x - 1, x + 2])
        return {"question": q, "options": opts, "answer_index": ans, "explain": f"Ø³ = ( {c} - {b} ) Ã· {a} = {x}"}

    if t == "percent":
        y = random.randint(20, 200)
        x = random.choice([5, 10, 12, 15, 20, 25, 30, 40, 50])
        val = round(y * x / 100)
        q = f"Ù…Ø§ {x}% Ù…Ù† {y} ØŸ"
        opts, ans = _choice4(val, [val + 5, val - 5, val + 10])
        return {"question": q, "options": opts, "answer_index": ans, "explain": f"{x}% Ã— {y} = {y * x / 100:g}"}

    if t == "pow":
        base = random.randint(2, 15)
        exp = random.choice([2, 3])
        val = base ** exp
        q = f"Ù‚ÙŠÙ…Ø© {base}^{exp} = ØŸ"
        near = [val + base, val - base, val + 2]
        opts, ans = _choice4(val, near)
        return {"question": q, "options": opts, "answer_index": ans, "explain": f"{base}^{exp} = {val}"}

    v = random.randint(30, 120)
    t = random.randint(1, 6)
    d = v * t
    q = f"Ø³ÙŠØ§Ø±Ø© Ø³Ø±Ø¹ØªÙ‡Ø§ {v} ÙƒÙ…/Ø³ØŒ Ø³Ø§Ø±Øª {t} Ø³Ø§Ø¹Ø§Øª. Ù…Ø§ Ø§Ù„Ù…Ø³Ø§ÙØ©ØŸ"
    opts, ans = _choice4(d, [d - 10, d + 10, d + v])
    return {"question": q, "options": opts, "answer_index": ans, "explain": "Ø§Ù„Ù…Ø³Ø§ÙØ© = Ø§Ù„Ø³Ø±Ø¹Ø© Ã— Ø§Ù„Ø²Ù…Ù†."}

# ---- Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù„ÙØ¸ÙŠ Ø§Ù„Ø¢Ù…Ù†Ø© ----
def _build_four_options(correct: str, wrong_candidates: List[str]) -> Tuple[List[str], int]:
    seen = set([correct])
    opts = [correct]
    for w in wrong_candidates:
        if w and w not in seen:
            opts.append(w)
            seen.add(w)
        if len(opts) == 4:
            break
    fillers = ["Ù‚Ø¯ÙŠÙ…", "Ø­Ø¯ÙŠØ«", "Ø³Ø±ÙŠØ¹", "Ø¨Ø·ÙŠØ¡", "ÙˆØ§Ø¶Ø­", "ØºØ§Ù…Ø¶", "Ù‚ÙˆÙŠ", "Ø¶Ø¹ÙŠÙ", "Ù‚Ø±ÙŠØ¨", "Ø¨Ø¹ÙŠØ¯"]
    for w in fillers:
        if len(opts) == 4:
            break
        if w not in seen:
            opts.append(w)
            seen.add(w)
    random.shuffle(opts)
    return opts, opts.index(correct)

# ---- Ù„ÙØ¸ÙŠ (Ù‚ÙˆØ§Ø¦Ù… Ù…ÙˆØ³Ù‘Ø¹Ø©) ----
SYN = [
    ("ÙŠØ¬Ø§Ø¨Ù‡", "ÙŠÙˆØ§Ø¬Ù‡"), ("Ø¬Ù„Ù‘ÙŠ", "ÙˆØ§Ø¶Ø­"), ("ÙŠÙ†Ø£Ù‰", "ÙŠØ¨ØªØ¹Ø¯"), ("ÙŠØ¨ØªÙƒØ±", "ÙŠØ¨Ø¯Ø¹"),
    ("Ù…Ø­Ù†Ø©", "Ø§Ø¨ØªÙ„Ø§Ø¡"), ("Ø³Ø§Ø·Ø¹", "Ù„Ø§Ù…Ø¹"), ("Ù…ØªÙŠÙ†", "Ù‚ÙˆÙŠ"), ("ÙˆØ¯ÙˆØ¯", "Ù„Ø·ÙŠÙ"),
    ("Ø«Ø§Ø¨Ø±", "ÙˆØ§Ø¸Ø¨"), ("ÙŠØ¹Ø²Ù‘Ø²", "ÙŠÙ‚ÙˆÙ‘ÙŠ"), ("ÙŠØ«Ø±ÙŠ", "ÙŠØºÙ†ÙŠ"), ("Ø±Ø´Ø§Ù‚Ø©", "Ø®ÙÙÙ‘Ø©"),
    ("Ø­ØµÙŠÙ", "Ø¹Ø§Ù‚Ù„"), ("Ø·Ù…Ø£Ù†ÙŠÙ†Ø©", "Ø³ÙƒÙˆÙ†"), ("Ø­Ø§Ø²Ù…", "ØµØ§Ø±Ù…"), ("ÙŠÙ„ØªØ²Ù…", "ÙŠØªÙ‚ÙŠØ¯"),
    ("ÙŠÙØ¬Ù…Ù‘Ù„", "ÙŠØ²ÙŠÙ†"), ("Ù…Ù‡Ø§Ø±Ø©", "Ø¨Ø±Ø§Ø¹Ø©"), ("ÙŠØ³ØªØ¹ÙŠØ¯", "ÙŠØ³ØªØ±Ø¬Ø¹"), ("Ù…ÙˆØ«ÙˆÙ‚", "Ø¬Ø¯ÙŠØ± Ø¨Ø§Ù„Ø«Ù‚Ø©"),
    ("Ø¬ÙˆÙ‡Ø±", "Ù„Ø¨Ù‘"), ("Ù…Ù„Ø­ÙˆØ¸", "Ø¨Ø§Ø±Ø²"), ("Ù…ÙÙ„Ù‡Ù…", "Ù…Ø´Ø¬Ù‘Ø¹"), ("ÙŠÙØ¨Ø±Ù‡Ù†", "ÙŠØ«Ø¨Øª")
]
ANT = [
    ("Ù…Ø¤Ù‚Ù‘Øª", "Ø¯Ø§Ø¦Ù…"), ("Ù‚ÙˆÙŠ", "Ø¶Ø¹ÙŠÙ"), ("ÙˆØ¶ÙˆØ­", "ØºÙ…ÙˆØ¶"), ("Ø³Ù‡Ù„", "ØµØ¹Ø¨"),
    ("Ù‚Ø¯ÙŠÙ…", "Ø­Ø¯ÙŠØ«"), ("Ù‚Ø±ÙŠØ¨", "Ø¨Ø¹ÙŠØ¯"), ("ÙˆÙØ±Ø©", "Ù‚Ù„Ù‘Ø©"), ("Ø­Ø§Ø¶Ø±", "ØºØ§Ø¦Ø¨"),
    ("Ù†Ø¬Ø§Ø­", "ÙØ´Ù„"), ("ÙŠÙ‚Ø¨Ù„", "ÙŠØ±ÙØ¶"), ("Ù†Ø¸Ø§Ù…", "ÙÙˆØ¶Ù‰"), ("Ø§Ù†Ø®ÙØ§Ø¶", "Ø§Ø±ØªÙØ§Ø¹"),
    ("Ø¨Ø§Ø±Ø¯", "Ø­Ø§Ø±"), ("Ø­ÙŠØ§Ø©", "Ù…ÙˆØª"), ("Ù†Ø´Ø§Ø·", "Ø®Ù…ÙˆÙ„"), ("Ø´Ø¬Ø§Ø¹", "Ø¬Ø¨Ø§Ù†"),
    ("Ù…ÙÙŠØ¯", "Ø¶Ø§Ø±"), ("Ù†Ø¸ÙŠÙ", "Ù…ØªØ³Ø®"), ("ÙØ±Ø­", "Ø­Ø²Ù†"), ("Ù†Ø§Ø¯Ø±", "Ø´Ø§Ø¦Ø¹"),
    ("ÙŠÙ…Ø¯Ø­", "ÙŠØ°Ù…"), ("Ø§Ù„ÙŠÙ‚ÙŠÙ†", "Ø§Ù„Ø´Ùƒ"), ("Ø¨Ø¯Ø§ÙŠØ©", "Ù†Ù‡Ø§ÙŠØ©"), ("Ù…Ø¨Ø§Ø´Ø±", "ØºÙŠØ± Ù…Ø¨Ø§Ø´Ø±")
]
COMP_SENT = [
    ("Ø§Ù„Ø·Ø§Ù„Ø¨ ____ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ.", "ØªÙÙˆÙ‚", ["ØªÙÙˆÙ‘Ù‚", "ØªØ£Ø®Ù‘Ø±", "ØªÙ‡Ø§ÙˆÙ†", "Ø§Ù†Ø³Ø­Ø¨"]),
    ("ÙƒØ§Ù† Ø§Ù„Ù‚Ø±Ø§Ø± ____ Ø¨Ø¹Ø¯ Ø¯Ø±Ø§Ø³Ø© Ù…Ø³ØªÙÙŠØ¶Ø©.", "ØµØ§Ø¦Ø¨", ["ØµØ§Ø¦Ø¨", "Ø¹Ø´ÙˆØ§Ø¦ÙŠ", "Ù…ÙÙ„ØªØ¨Ø³", "Ù…ØªØ³Ø±Ù‘Ø¹"]),
    ("ÙŠØ¬Ø¨ _____ Ø§Ù„ÙˆÙ‚Øª Ù„ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù.", "Ø§Ø³ØªØ«Ù…Ø§Ø±", ["Ø¥Ù‡Ø¯Ø§Ø±", "ØªØ¶ÙŠÙŠØ¹", "Ø§Ø³ØªØ«Ù…Ø§Ø±", "ØªØ¬Ù…ÙŠØ¯"]),
    ("Ø§Ù„ÙÙƒØ±Ø© Ù…Ø§ Ø²Ø§Ù„Øª ____ ÙˆØªØ­ØªØ§Ø¬ ØªÙˆØ¶ÙŠØ­Ù‹Ø§.", "ØºØ§Ù…Ø¶Ø©", ["ÙˆØ§Ø¶Ø­Ø©", "ØºØ§Ù…Ø¶Ø©", "Ù‚ÙˆÙŠØ©", "Ù‚Ø¯ÙŠÙ…Ø©"]),
    ("Ù†Ø¬Ø­ Ø§Ù„ÙØ±ÙŠÙ‚ Ø¨ÙØ¶Ù„ ____ Ø§Ù„Ø¬Ù‡ÙˆØ¯.", "ØªÙƒØ§Ù…Ù„", ["ØªÙÙƒÙƒ", "ØªÙƒØ§Ø³Ù„", "ØªÙƒØ§Ù…Ù„", "ØªØ¨Ø§Ø¹Ø¯"]),
    ("Ø£Ø¸Ù‡Ø±Øª Ø§Ù„ØªØ¬Ø±Ø¨Ø© ____ Ø§Ù„ÙØ±Ø¶ÙŠØ©.", "ØµØ­Ø©", ["Ø³Ù‚ÙˆØ·", "ØµØ­Ø©", "Ø¶Ø¹Ù", "ØºÙ…ÙˆØ¶"]),
    ("Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© ____ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª.", "ØªØ«Ø±ÙŠ", ["ØªØ¶Ø¹Ù", "ØªØ«Ø±ÙŠ", "ØªØ¨Ø¯Ø¯", "ØªÙ‚Ù„Ù„"]),
    ("Ø¨Ø¹Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø´ØŒ ÙˆØµÙ„Ù†Ø§ Ø¥Ù„Ù‰ ____ Ù…Ø´ØªØ±ÙƒØ©.", "Ø±Ø¤ÙŠØ©", ["Ø±Ø¤ÙŠØ©", "ÙÙˆØ¶Ù‰", "ØªØ±Ø¯Ø¯", "Ø®Ù„Ø§Ù"]),
    ("Ø§Ù„Ø®Ø¨Ø± Ø§Ù„ÙŠÙ‚ÙŠÙ† Ø£ÙØ¶Ù„ Ù…Ù† ____ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø§Øª.", "ØºÙ…ÙˆØ¶", ["ÙˆØ¶ÙˆØ­", "ØºÙ…ÙˆØ¶", "Ø§Ù†ØªØ´Ø§Ø±", "Ù‚Ø¯Ù…"]),
    ("Ø§Ù„Ø·Ø§Ù„Ø¨ Ø§Ù„Ù…Ø¬ØªÙ‡Ø¯ ____ Ø®Ø·ØªÙ‡ Ø£Ø³Ø¨ÙˆØ¹ÙŠÙ‹Ø§.", "ÙŠØ±Ø§Ø¬Ø¹", ["ÙŠÙ‡Ù…Ù„", "ÙŠØ±Ø§Ø¬Ø¹", "ÙŠÙ†Ø³Ù‰", "ÙŠØªØ¬Ø§Ù‡Ù„"]),
    ("Ù…Ù† Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠ ____ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ù„ØªØ¬Ù†Ù‘Ø¨ ØªÙƒØ±Ø§Ø±Ù‡Ø§.", "ØªØ­Ù„ÙŠÙ„", ["ØªØ­Ù„ÙŠÙ„", "Ø¥Ù†ÙƒØ§Ø±", "Ø¥Ù‡Ù…Ø§Ù„", "ØªØ¬Ø§Ù‡Ù„"]),
    ("Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙƒØ§Ù†Øª ____ Ù„Ù„ØªÙˆÙ‚Ø¹Ø§Øª.", "Ù…Ø·Ø§Ø¨Ù‚Ø©", ["Ù…ØªØ£Ø®Ø±Ø©", "Ù…Ø®Ø§Ù„ÙØ©", "Ù…Ø·Ø§Ø¨Ù‚Ø©", "ØºØ§Ù…Ø¶Ø©"]),
    ("Ù„Ø§ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ ____ Ø¯ÙˆÙ† Ø¯Ù„ÙŠÙ„.", "Ø§Ù„Ø§Ù†Ø·Ø¨Ø§Ø¹", ["Ø§Ù„Ø§Ù†Ø·Ø¨Ø§Ø¹", "Ø§Ù„Ø¨Ø±Ù‡Ø§Ù†", "Ø§Ù„Ù…Ø«Ø§Ù„", "Ø§Ù„Ø´Ø±Ø­"]),
    ("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªÙÙ‚Ø¯Ù‘ÙÙ… Ø¨ØµÙˆØ±Ø© ____ ÙˆÙˆØ§Ø¶Ø­Ø©.", "Ù…Ù†Ø¸Ù‘Ù…Ø©", ["Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©", "Ù…Ù†Ø¸Ù‘Ù…Ø©", "Ø³Ø·Ø­ÙŠØ©", "Ù†Ø§Ù‚ØµØ©"]),
    ("Ù†Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ ____ Ø¯Ù‚ÙŠÙ‚Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±.", "Ù…Ø±Ø§Ø¬Ø¹Ø©", ["Ù…Ø±Ø§Ø¬Ø¹Ø©", "ØªØ³Ù„ÙŠØ©", "Ø¥Ù‡Ù…Ø§Ù„", "ØªØ´ØªÙŠØª"]),
]

def gen_verbal() -> Dict[str, Any]:
    kind = random.choice(["syn", "ant", "analogy", "cloze"])
    if kind == "syn":
        a, b = random.choice(SYN)
        wrongs = [w for _, w in SYN if w != b] + [x for _, x in ANT]
        opts, idx = _build_four_options(b, wrongs)
        return {"question": f"Ù…Ø±Ø§Ø¯Ù Â«{a}Â» Ù‡Ùˆ:", "options": opts, "answer_index": idx, "explain": f"Ù…Ø±Ø§Ø¯Ù Â«{a}Â» = Â«{b}Â»."}
    if kind == "ant":
        a, b = random.choice(ANT)
        wrongs = [w for _, w in ANT if w != b] + [x for _, x in SYN]
        opts, idx = _build_four_options(b, wrongs)
        return {"question": f"Ø¶Ø¯Ù‘ Â«{a}Â» Ù‡Ùˆ:", "options": opts, "answer_index": idx, "explain": f"Ø¶Ø¯Ù‘ Â«{a}Â» = Â«{b}Â»."}
    if kind == "analogy":
        if random.random() < 0.5:
            a, b = random.choice(SYN)
            c, d = random.choice(SYN)
            q = f"{a} : {b} :: {c} : ØŸ"
            target = d
            pool = [x for _, x in SYN if x != d] + [x for _, x in ANT]
        else:
            a, b = random.choice(ANT)
            c, d = random.choice(ANT)
            q = f"{a} : {b} :: {c} : ØŸ"
            target = d
            pool = [x for _, x in ANT if x != d] + [x for _, x in SYN]
        opts, idx = _build_four_options(target, pool)
        return {"question": q, "options": opts, "answer_index": idx, "explain": "Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© ÙŠÙ…ÙŠÙ† Ø§Ù„ØªØ´Ø¨ÙŠÙ‡."}
    s, correct, opts_full = random.choice(COMP_SENT)
    opts, idx = _build_four_options(correct, [o for o in opts_full if o != correct])
    return {"question": s, "options": opts, "answer_index": idx, "explain": f"Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ø£Ù†Ø³Ø¨: Â«{correct}Â»."}

# ---- Ø°ÙƒØ§Ø¡ ----
AR_LETTERS = list("Ø§Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠ")

def gen_iq() -> Dict[str, Any]:
    k = random.choice(["arith_seq", "geom_seq", "alt_seq", "letter_seq", "squares", "fibo", "mix_ops"])
    if k == "arith_seq":
        a = random.randint(1, 15)
        d = random.randint(2, 9)
        n = [a + i * d for i in range(5)]
        ans = n[-1] + d
        opts, idx = _choice4(ans, [ans + d, ans - d, ans + 2])
        return {"question": f"Ø£ÙƒÙ…Ù„ Ø§Ù„Ù…ØªØªØ§Ù„ÙŠØ©: {', '.join(map(str, n))}, ØŸ", "options": opts, "answer_index": idx, "explain": f"ÙØ±Ù‚ Ø«Ø§Ø¨Øª = {d}"}
    if k == "geom_seq":
        a = random.randint(1, 6)
        r = random.choice([2, 3, 4])
        n = [a * (r ** i) for i in range(4)]
        ans = n[-1] * r
        opts, idx = _choice4(ans, [ans * r, ans // r if ans % r == 0 else ans - 1, ans + r])
        return {"question": f"Ø£ÙƒÙ…Ù„: {', '.join(map(str, n))}, ØŸ", "options": opts, "answer_index": idx, "explain": f"Ù…ØªØ¶Ø§Ø¹Ù Ø¨Ù†Ø³Ø¨Ø© {r}"}
    if k == "alt_seq":
        a = random.randint(5, 20)
        d1 = random.randint(2, 6)
        d2 = random.randint(7, 12)
        seq = [a, a + d1, a + d1 + d2, a + 2 * d1 + d2, a + 2 * d1 + 2 * d2]
        ans = a + 3 * d1 + 2 * d2
        opts, idx = _choice4(ans, [ans + d1, ans + d2, ans - 1])
        return {"question": f"Ù†Ù…Ø· Ù…ØªÙ†Ø§ÙˆØ¨ (+{d1}, +{d2}): {', '.join(map(str, seq))}, ØŸ", "options": opts, "answer_index": idx, "explain": "ÙŠØ²ÙŠØ¯ Ù…Ø±Ù‘Ø© d1 Ø«Ù… d2 Ø¨Ø§Ù„ØªÙ†Ø§ÙˆØ¨."}
    if k == "letter_seq":
        step = random.randint(1, 3)
        max_start = len(AR_LETTERS) - 1 - 5 * step
        if max_start < 0:
            step = 1
            max_start = len(AR_LETTERS) - 6
        start = random.randint(0, max_start)
        seq = [AR_LETTERS[start + i * step] for i in range(5)]
        nxt_index = start + 5 * step
        nxt = AR_LETTERS[nxt_index]
        candidates = [i for i in range(len(AR_LETTERS)) if i != nxt_index]
        wrong_idx = random.sample(candidates, 3)
        opts = [nxt] + [AR_LETTERS[i] for i in wrong_idx]
        random.shuffle(opts)
        return {"question": f"Ø£ÙƒÙ…Ù„: {'ØŒ '.join(seq)}, ØŸ", "options": opts, "answer_index": opts.index(nxt), "explain": f"Ø²ÙŠØ§Ø¯Ø© Ø«Ø§Ø¨ØªØ© Ø¨Ø§Ù„Ø­Ø±ÙˆÙ Ø¨Ù…Ù‚Ø¯Ø§Ø± {step}."}
    if k == "squares":
        s = random.randint(2, 6)
        seq = [i * i for i in range(s, s + 4)]
        ans = (s + 4) ** 2
        opts, idx = _choice4(ans, [ans + (2 * s + 1), ans - (2 * s + 1), ans + 4])
        return {"question": f"Ù…Ø±Ø¨Ø¹Ø§Øª: {', '.join(map(str, seq))}, ØŸ", "options": opts, "answer_index": idx, "explain": "Ø£Ù†Ù…Ø§Ø· nÂ²."}
    if k == "fibo":
        a, b = random.randint(1, 4), random.randint(1, 4)
        seq = [a, b]
        for _ in range(3):
            seq.append(seq[-1] + seq[-2])
        ans = seq[-1] + seq[-2]
        opts, idx = _choice4(ans, [ans + seq[-3], ans - 1, ans + 2])
        return {"question": f"ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ: {', '.join(map(str, seq))}, ØŸ", "options": opts, "answer_index": idx, "explain": "ÙƒÙ„ Ø­Ø¯ = Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚ÙŠÙ†."}
    a = random.randint(2, 6)
    b = random.choice([2, 3])
    x = random.randint(2, 9)
    seq = [x, x + a, (x + a) * b, (x + a) * b + a, ((x + a) * b + a) * b]
    ans = seq[-1] + a
    opts, idx = _choice4(ans, [ans + a, ans * b, ans - 1])
    return {"question": f"Ù†Ù…Ø· (+{a} Ø«Ù… Ã—{b}): {', '.join(map(str, seq))}, ØŸ", "options": opts, "answer_index": idx, "explain": f"ÙŠØªÙ†Ø§ÙˆØ¨ +{a} Ø«Ù… Ã—{b}."}

# ======================================================
#                    Ù…Ø­Ø±Ù‘Ùƒ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
# ======================================================
class QuizSession:
    def __init__(self, generator, limit: int):
        self.gen = generator
        self.total = limit
        self.idx = 0
        self.correct = 0
        self.items: List[Dict[str, Any]] = []

    def _ensure(self):
        while len(self.items) <= self.idx and len(self.items) < self.total:
            try:
                self.items.append(self.gen())
            except Exception as e:
                log.exception("generator failed, falling back", exc_info=e)
                self.items.append({
                    "question": "Ø£ÙƒÙ…Ù„: 2ØŒ 4ØŒ 6ØŒ 8ØŒ ØŸ",
                    "options": ["9", "10", "12", "14"],
                    "answer_index": 1,
                    "explain": "ÙØ±Ù‚ Ø«Ø§Ø¨Øª +2 â†’ 10"
                })

    def current(self) -> Optional[Dict[str, Any]]:
        self._ensure()
        return self.items[self.idx] if self.idx < self.total else None

    def check(self, choice: int) -> Dict[str, Any]:
        q = self.current()
        if not q:
            return {"done": True}
        ok = (choice == q["answer_index"])
        if ok:
            self.correct += 1
        self.idx += 1
        return {"ok": ok, "answer_index": q["answer_index"], "explain": q.get("explain")}

def fmt_progress(i: int, total: int) -> str:
    blocks = 10
    fill = int((i / total) * blocks)
    return "â– " * fill + "â–¡" * (blocks - fill) + f" {i}/{total}"

def q_text(q: Dict[str, Any], idx: int, total: int, label: str) -> Tuple[str, InlineKeyboardMarkup]:
    letters = ["Ø£", "Ø¨", "Ø¬", "Ø¯", "Ù‡Ù€", "Ùˆ", "Ø²", "Ø­"]
    opts = q["options"]
    kb = [[InlineKeyboardButton(f"{letters[i]}) {opts[i]}", callback_data=f"ans|{i}")]
          for i in range(len(opts))]
    text = f"ğŸ§  {label}\nØ§Ù„Ø³Ø¤Ø§Ù„ {idx + 1} Ù…Ù† {total}\n{fmt_progress(idx, total)}\n\n{q['question']}"
    return text, InlineKeyboardMarkup(kb)

def session_get(context: ContextTypes.DEFAULT_TYPE, cat: str) -> QuizSession:
    store = context.user_data.setdefault("sessions", {})
    s = store.get(cat)
    if s and isinstance(s, QuizSession):
        return s
    limit = 500 if cat in ("quant", "verbal") else 300
    gen = gen_quant if cat == "quant" else gen_verbal if cat == "verbal" else gen_iq
    s = QuizSession(gen, limit)
    store[cat] = s
    return s

async def send_next(update: Update, context: ContextTypes.DEFAULT_TYPE, cat: str, label: str):
    s = session_get(context, cat)
    for _ in range(6):
        q = s.current()
        if not q:
            break
        fingerprint = q["question"]
        if not seen_has(context, cat, fingerprint):
            seen_push(context, cat, fingerprint)
            break
        s.items[s.idx] = s.gen()
    q = s.current()
    if not q:
        await update.effective_message.reply_text(
            f"Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± âœ…\nØ§Ù„Ù†ØªÙŠØ¬Ø©: {s.correct}/{s.total}",
            reply_markup=ReplyKeyboardMarkup(MAIN_BTNS, resize_keyboard=True)
        )
        context.user_data["sessions"].pop(cat, None)
        return
    txt, kb = q_text(q, s.idx, s.total, label)
    context.user_data["last_cat"] = cat
    await update.effective_message.reply_text(txt, reply_markup=kb)

# ======================================================
#                     ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
# ======================================================
MAIN_BTNS = [
    [KeyboardButton("Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¶Ø±Ø¨")],
    [KeyboardButton("Ù‚Ø¯Ø±Ø§Øª ÙƒÙ…ÙŠ (500 Ø³Ø¤Ø§Ù„)")],
    [KeyboardButton("Ù‚Ø¯Ø±Ø§Øª Ù„ÙØ¸ÙŠ (500 Ø³Ø¤Ø§Ù„)")],
    [KeyboardButton("Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ (300 Ø³Ø¤Ø§Ù„)")],
    [KeyboardButton("Ø§Ø³Ø£Ù„ Ù…Ø­Ù…Ø¯ Ù…Ø´Ø±Ù")],
]
MAIN_KB = ReplyKeyboardMarkup(MAIN_BTNS, resize_keyboard=True)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Ù…Ø±Ø­Ø¨Ù‹Ø§! Ø§Ø®ØªØ± Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ğŸ‘‡", reply_markup=MAIN_KB)

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "/start Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©\n/quant ÙƒÙ…ÙŠ\n/verbal Ù„ÙØ¸ÙŠ\n/iq Ø°ÙƒØ§Ø¡\n/table Ø¬Ø¯ÙˆÙ„ Ø¶Ø±Ø¨\n"
        "/ask_ai Ø³Ø¤Ø§Ù„Ùƒ  (Ø£Ùˆ Ø§Ø¶ØºØ· Ø²Ø±: Ø§Ø³Ø£Ù„ Ù…Ø­Ù…Ø¯ Ù…Ø´Ø±Ù)\n"
        "/ai_prefs Ø¹Ø±Ø¶ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡\n/ai_model ØªØºÙŠÙŠØ± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„\n"
        "/ai_temp ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø±Ø§Ø±Ø©\n/ai_style ØªØºÙŠÙŠØ± Ø§Ù„Ø£Ø³Ù„ÙˆØ¨\n/ai_diag ÙØ­Øµ Ø§Ù„Ø°ÙƒØ§Ø¡\n"
        "/ei_on ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¹Ø§Ø·Ù\n/ei_off Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ¹Ø§Ø·Ù"
    )

# ====== Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¶Ø±Ø¨ ======
def parse_mul_expr(s: str) -> Tuple[bool, int, int]:
    s = s.replace("Ã—", "x").replace("X", "x").replace("*", "x")
    m = re.fullmatch(r"\s*(-?\d+)\s*x\s*(-?\d+)\s*", s)
    if not m:
        return False, 0, 0
    return True, int(m.group(1)), int(m.group(2))

def mult_table(n: int, upto: int = 12) -> str:
    rows = [f"ğŸ“ Ø¬Ø¯ÙˆÙ„ Ø¶Ø±Ø¨ {n}:"]
    for i in range(1, upto + 1):
        rows.append(f"{n} Ã— {i} = {n * i}")
    return "\n".join(rows)

def clean_number_only(text: str) -> Optional[int]:
    t = text.strip()
    m = re.fullmatch(r"(-?\d+)", t)
    return int(m.group(1)) if m else None

# ====== Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ù„Ø¨Ù‘ Ø§Ù„ØªÙ†ÙÙŠØ°) ======
async def _ask_ai_core(update: Update, context: ContextTypes.DEFAULT_TYPE, q: Optional[str]):
    if not q:
        await update.message.reply_text("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø¨Ø¹Ø¯ Ø§Ù„Ø£Ù…Ø±:\n/ask_ai ÙƒÙŠÙ Ø£Ø°Ø§ÙƒØ± Ø§Ù„Ù‚Ø¯Ø±Ø§ØªØŸ")
        return
    if not AI_API_KEY:
        await update.message.reply_text("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø¶Ø¨Ø· AI_API_KEY ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù… (Render).")
        return

    prefs = get_ai_prefs(context)
    ei_enabled = get_ei(context)
    system_msg = ai_system_prompt(prefs["style"], ei_enabled)

    try:
        await update.effective_chat.send_action(ChatAction.TYPING)
        try:
            from openai import OpenAI
        except ModuleNotFoundError:
            await update.message.reply_text("âŒ Ù…ÙƒØªØ¨Ø© openai ØºÙŠØ± Ù…Ø«Ø¨ØªØ©. Ø£Ø¶Ù Ø¥Ù„Ù‰ requirements.txt:\nopenai>=1.35.0")
            return

        client = OpenAI(api_key=AI_API_KEY, base_url=AI_BASE_URL) if AI_BASE_URL else OpenAI(api_key=AI_API_KEY)

        def _call():
            return client.chat.completions.create(
                model=prefs["model"],
                temperature=prefs["temperature"],
                max_tokens=AI_MAX_TOKENS,
                messages=[
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": q}
                ],
            )

        resp = await asyncio.wait_for(asyncio.to_thread(_call), timeout=25)
        answer = (resp.choices[0].message.content or "").strip() or "Ù„Ù… Ø£Ø³ØªØ·Ø¹ ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø¢Ù†."
        for i in range(0, len(answer), 4000):
            await update.message.reply_text(answer[i:i + 4000])

    except asyncio.TimeoutError:
        await update.message.reply_text("â±ï¸ Ø§Ù†ØªÙ‡Øª Ø§Ù„Ù…Ù‡Ù„Ø©. Ø¬Ø±Ù‘Ø¨ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø£Ù‚ØµØ± Ø£Ùˆ Ø£Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©.")
    except Exception as e:
        msg = str(e)
        if "401" in msg or "Unauthorized" in msg or "Incorrect API key" in msg:
            hint = "ØªØ­Ù‚Ù‘Ù‚ Ù…Ù† AI_API_KEY (ÙŠØ¨Ø¯Ø£ Ø¨Ù€ sk-)."
        elif "model" in msg and ("not found" in msg or "does not exist" in msg):
            hint = f"Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ØºÙŠØ± ØµØ­ÙŠØ­. Ø§Ù„Ø­Ø§Ù„ÙŠ: {prefs['model']}"
        elif "429" in msg or "rate limit" in msg:
            hint = "ØªØ¬Ø§ÙˆØ²Øª Ø­Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…. Ø§Ù†ØªØ¸Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ø«Ù… Ø£Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©."
        else:
            hint = "ØªØ¹Ø°Ù‘Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø¯Ù…Ø©."
        await update.message.reply_text(f"âŒ Ø®Ø·Ø£ ÙÙŠ /ask_ai:\n{msg}\nØ§Ù„Ø§Ù‚ØªØ±Ø§Ø­: {hint}")

# ====== Ù…ÙˆØ¬Ù‘Ù‡ Ø§Ù„Ù†Øµ ======
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    t = (update.message.text or "").strip()

    # âœ… ÙˆØ¶Ø¹ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±: Ø£Ø±Ø³Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© Ù„Ù„Ø°ÙƒØ§Ø¡ Ù…Ø¨Ø§Ø´Ø±Ø©
    if context.user_data.pop("ai_wait", False) and not t.startswith("/"):
        await _ask_ai_core(update, context, t)
        return

    if "Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¶Ø±Ø¨" in t:
        await update.message.reply_text("Ø£Ø±Ø³Ù„ Ø±Ù‚Ù…Ù‹Ø§ (Ù…Ø«Ù„ 7) Ù„Ø¬Ø¯ÙˆÙ„ ÙƒØ§Ù…Ù„ØŒ Ø£Ùˆ ØµÙŠØºØ© (7Ã—7 / 7x7) Ù„Ù†Ø§ØªØ¬ ÙÙˆØ±ÙŠ.")
        return

    if "ÙƒÙ…ÙŠ" in t:
        context.user_data.get("sessions", {}).pop("quant", None)
        context.user_data["streak"] = 0
        await update.message.reply_text("Ø³ÙŠØ¨Ø¯Ø£ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒÙ…ÙŠ (Ø­ØªÙ‰ Ù¥Ù Ù ). Ø¨Ø§Ù„ØªÙˆÙÙŠÙ‚! ğŸ’ª")
        await send_next(update, context, "quant", "Ù‚Ø¯Ø±Ø§Øª ÙƒÙ…ÙŠ")
        return

    if "Ù„ÙØ¸ÙŠ" in t:
        context.user_data.get("sessions", {}).pop("verbal", None)
        context.user_data["streak"] = 0
        await update.message.reply_text("Ø³ÙŠØ¨Ø¯Ø£ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù„ÙØ¸ÙŠ (Ø­ØªÙ‰ Ù¥Ù Ù ). Ø±ÙƒÙ‘Ø² ğŸ‘€")
        await send_next(update, context, "verbal", "Ù‚Ø¯Ø±Ø§Øª Ù„ÙØ¸ÙŠ")
        return

    if "Ø§Ù„Ø°ÙƒØ§Ø¡" ÙÙŠ t or "Ø°ÙƒØ§Ø¡" in t:
        context.user_data.get("sessions", {}).pop("iq", None)
        context.user_data["streak"] = 0
        await update.message.reply_text("Ø³ÙŠØ¨Ø¯Ø£ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø°ÙƒØ§Ø¡ (Ø­ØªÙ‰ Ù£Ù Ù ).")
        await send_next(update, context, "iq", "Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø°ÙƒØ§Ø¡")
        return

    if "Ø§Ø³Ø£Ù„ Ù…Ø­Ù…Ø¯ Ù…Ø´Ø±Ù" in t:
        context.user_data["ai_wait"] = True
        await update.message.reply_text("âœï¸ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ø¢Ù† Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¯ÙˆÙ† Ø£ÙˆØ§Ù…Ø±.")
        return

    # ØªØ¹Ø¨ÙŠØ± Ø¶Ø±Ø¨ Ù…Ø¨Ø§Ø´Ø±
    ok, a, b = parse_mul_expr(t)
    if ok:
        await update.message.reply_text(f"{a} Ã— {b} = {a * b}")
        return

    # Ø±Ù‚Ù… ÙÙ‚Ø· â†’ Ø¬Ø¯ÙˆÙ„ ÙƒØ§Ù…Ù„
    n = clean_number_only(t)
    if n is not None:
        await update.message.reply_text(mult_table(n))
        return

    await update.message.reply_text("Ø§Ø®ØªØ± Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ùˆ /help", reply_markup=MAIN_KB)

# ====== Ø£ÙˆØ§Ù…Ø± Ù…Ø®ØªØµØ±Ø© ======
async def cmd_quant(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.get("sessions", {}).pop("quant", None)
    context.user_data["streak"] = 0
    await send_next(update, context, "quant", "Ù‚Ø¯Ø±Ø§Øª ÙƒÙ…ÙŠ")

async def cmd_verbal(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.get("sessions", {}).pop("verbal", None)
    context.user_data["streak"] = 0
    await send_next(update, context, "verbal", "Ù‚Ø¯Ø±Ø§Øª Ù„ÙØ¸ÙŠ")

async def cmd_iq(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.get("sessions", {}).pop("iq", None)
    context.user_data["streak"] = 0
    await send_next(update, context, "iq", "Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø°ÙƒØ§Ø¡")

async def cmd_ei_on(update: Update, context: ContextTypes.DEFAULT_TYPE):
    set_ei(context, True)
    await update.message.reply_text("ØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ âœ…")

async def cmd_ei_off(update: Update, context: ContextTypes.DEFAULT_TYPE):
    set_ei(context, False)
    await update.message.reply_text("ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ â›”ï¸")

# ====== Ø§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„Ø£Ø²Ø±Ø§Ø± ======
async def cb_answer(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    m = re.fullmatch(r"ans\|(\d+)", (query.data or ""))
    if not m:
        return
    choice = int(m.group(1))

    cat = context.user_data.get("last_cat")
    if cat not in ("quant", "verbal", "iq"):
        await query.edit_message_text("Ø§Ù†ØªÙ‡Øª Ø§Ù„Ø¬Ù„Ø³Ø©. Ø§Ø¨Ø¯Ø£ Ù…Ù† Ø¬Ø¯ÙŠØ¯ /start")
        return

    s = session_get(context, cat)
    res = s.check(choice)
    right_letter = ["Ø£", "Ø¨", "Ø¬", "Ø¯", "Ù‡Ù€", "Ùˆ", "Ø²", "Ø­"][res["answer_index"]]
    streak = context.user_data.get("streak", 0)

    if res["ok"]:
        streak += 1
        context.user_data["streak"] = streak
        msg = f"âœ”ï¸ ØµØ­ÙŠØ­! ({s.correct}/{s.total})"
        if get_ei(context):
            msg += "\n" + ei_msg_correct(streak)
    else:
        context.user_data["streak"] = 0
        msg = f"âŒ Ø®Ø·Ø£.\nØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©: {right_letter}"
        if get_ei(context):
            msg += "\n" + ei_msg_wrong(res.get("explain"))

    await query.edit_message_text(msg)
    label = "Ù‚Ø¯Ø±Ø§Øª ÙƒÙ…ÙŠ" if cat == "quant" else "Ù‚Ø¯Ø±Ø§Øª Ù„ÙØ¸ÙŠ" if cat == "verbal" else "Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø°ÙƒØ§Ø¡"
    await send_next(update, context, cat, label)

# ====== Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ: Ø£Ù…Ø± /ask_ai (ØºÙ„Ø§Ù ÙŠØ³ØªØ¯Ø¹ÙŠ Ø§Ù„Ù„Ø¨) ======
async def ask_ai(update: Update, context: ContextTypes.DEFAULT_TYPE):
    txt = (update.message.text or "")
    q = None
    if txt.startswith("/ask_ai") and " " in txt:
        q = txt.split(" ", 1)[1].strip()
    elif update.message and update.message.reply_to_message:
        q = (update.message.reply_to_message.text or "").strip()
    await _ask_ai_core(update, context, q)

# ====== Ø£ÙˆØ§Ù…Ø± ØªØ­ÙƒÙ… ÙˆØªØ´Ø®ÙŠØµ AI ======
async def cmd_ai_style(update: Update, context: ContextTypes.DEFAULT_TYPE):
    args = (update.message.text or "").split()
    if len(args) < 2 or args[1] not in ("concise", "detailed"):
        await update.message.reply_text("Ø§Ø³ØªØ®Ø¯Ù…: /ai_style concise Ø£Ùˆ /ai_style detailed")
        return
    prefs = get_ai_prefs(context)
    prefs["style"] = args[1]
    await update.message.reply_text(f"ØªÙ… Ø¶Ø¨Ø· Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰: {args[1]}")

async def cmd_ai_temp(update: Update, context: ContextTypes.DEFAULT_TYPE):
    args = (update.message.text or "").split()
    if len(args) < 2:
        await update.message.reply_text("Ø§Ø³ØªØ®Ø¯Ù…: /ai_temp 0.2 Ø¥Ù„Ù‰ 1.5")
        return
    try:
        t = float(args[1])
        if not (0.0 <= t <= 1.5):
            raise ValueError()
    except Exception:
        await update.message.reply_text("Ù‚ÙŠÙ…Ø© ØºÙŠØ± ØµØ§Ù„Ø­Ø©. Ø§Ø®ØªØ± Ø±Ù‚Ù…Ù‹Ø§ Ø¨ÙŠÙ† 0.0 Ùˆ 1.5")
        return
    prefs = get_ai_prefs(context)
    prefs["temperature"] = t
    await update.message.reply_text(f"ØªÙ… Ø¶Ø¨Ø· Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø¹Ù„Ù‰: {t:g}")

async def cmd_ai_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    args = (update.message.text or "").split(maxsplit=1)
    if len(args) < 2:
        await update.message.reply_text("Ø§Ø³ØªØ®Ø¯Ù…: /ai_model Ø§Ø³Ù…_Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Ù…Ø«Ø§Ù„: gpt-4o-mini)")
        return
    prefs = get_ai_prefs(context)
    prefs["model"] = args[1].strip()
    await update.message.reply_text(f"ØªÙ… Ø¶Ø¨Ø· Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù„Ù‰: {prefs['model']}")

async def cmd_ai_prefs(update: Update, context: ContextTypes.DEFAULT_TYPE):
    prefs = get_ai_prefs(context)
    await update.message.reply_text(
        "Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø­Ø§Ù„ÙŠØ©:\n"
        f"- Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„: {prefs['model']}\n"
        f"- Ø§Ù„Ø­Ø±Ø§Ø±Ø©: {prefs['temperature']}\n"
        f"- Ø§Ù„Ø£Ø³Ù„ÙˆØ¨: {prefs['style']} (concise|detailed)\n"
        f"- Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ: {'Ù…ÙØ¹Ù‘Ù„' if get_ei(context) else 'Ù…ØªÙˆÙ‚Ù'}\n"
        f"- AI_BASE_URL: {AI_BASE_URL or 'Ø§ÙØªØ±Ø§Ø¶ÙŠ OpenAI'}"
    )

async def cmd_ai_diag(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        from openai import OpenAI
    except ModuleNotFoundError:
        await update.message.reply_text("âŒ Ù…ÙƒØªØ¨Ø© openai ØºÙŠØ± Ù…Ø«Ø¨ØªØ©. Ø£Ø¶Ù Ø¥Ù„Ù‰ requirements.txt:\nopenai>=1.35.0")
        return
    if not AI_API_KEY:
        await update.message.reply_text("âŒ AI_API_KEY ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ· ÙÙŠ Render.")
        return
    prefs = get_ai_prefs(context)
    try:
        client = OpenAI(api_key=AI_API_KEY, base_url=AI_BASE_URL) if AI_BASE_URL else OpenAI(api_key=AI_API_KEY)
        def _call():
            return client.chat.completions.create(
                model=prefs["model"], temperature=0.0, max_tokens=20,
                messages=[{"role": "user", "content": "Ø£Ø¬Ø¨ Ø¨ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©: Ù†Ø¹Ù…"}],
            )
        r = await asyncio.wait_for(asyncio.to_thread(_call), timeout=15)
        txt = (r.choices[0].message.content or "").strip()
        await update.message.reply_text(f"âœ… Ø§Ù„Ø§ØªØµØ§Ù„ Ù†Ø§Ø¬Ø­. Ø±Ø¯Ù‘ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {txt}")
    except Exception as e:
        await update.message.reply_text(
            f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„:\n{e}\nØªØ­Ù‚Ù‘Ù‚ Ù…Ù† AI_BASE_URL/AI_API_KEY/AI_MODEL ÙˆØ¥ØµØ¯Ø§Ø± Ù…ÙƒØªØ¨Ø© openai."
        )

# ====== Ù…ÙØ¹Ø§Ù„Ø¬ Ø£Ø®Ø·Ø§Ø¡ Ø¹Ø§Ù… ======
async def on_error(update: object, context: ContextTypes.DEFAULT_TYPE):
    log.exception("Exception in handler", exc_info=context.error)
    try:
        if isinstance(update, Update) and update.effective_message:
            await update.effective_message.reply_text("âš ï¸ ØµØ§Ø± Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ù‘Ø¹ ÙˆØªÙ… ØªØ³Ø¬ÙŠÙ„Ù‡. Ø¬Ø±Ù‘Ø¨ Ø§Ù„Ø£Ù…Ø± Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
    except Exception:
        pass

# ================= ØªØ´ØºÙŠÙ„ (Webhook ÙÙ‚Ø·) =================
def build() -> Application:
    app = Application.builder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("quant", cmd_quant))
    app.add_handler(CommandHandler("verbal", cmd_verbal))
    app.add_handler(CommandHandler("iq", cmd_iq))
    app.add_handler(CommandHandler("table", lambda u, c: u.message.reply_text("Ø£Ø±Ø³Ù„ Ø±Ù‚Ù…Ù‹Ø§ (7) Ù„Ø¬Ø¯ÙˆÙ„ØŒ Ø£Ùˆ 7Ã—9 Ù„Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ÙÙˆØ±ÙŠ")))
    app.add_handler(CommandHandler("ei_on", cmd_ei_on))
    app.add_handler(CommandHandler("ei_off", cmd_ei_off))
    app.add_handler(CommandHandler("ask_ai", ask_ai))
    # Ø£ÙˆØ§Ù…Ø± ØªØ­ÙƒÙ… ÙˆØªØ´Ø®ÙŠØµ AI
    app.add_handler(CommandHandler("ai_style", cmd_ai_style))
    app.add_handler(CommandHandler("ai_temp", cmd_ai_temp))
    app.add_handler(CommandHandler("ai_model", cmd_ai_model))
    app.add_handler(CommandHandler("ai_prefs", cmd_ai_prefs))
    app.add_handler(CommandHandler("ai_diag", cmd_ai_diag))
    app.add_handler(CallbackQueryHandler(cb_answer, pattern=r"^ans\|"))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_error_handler(on_error)
    return app

def main():
    app = build()
    log.info("Webhook on %s", WEBHOOK_URL)
    app.run_webhook(
        listen="0.0.0.0",
        port=PORT,
        url_path=BOT_TOKEN,
        webhook_url=f"{WEBHOOK_URL}/{BOT_TOKEN}",
        drop_pending_updates=True,
    )

if __name__ == "__main__":
    main()
