# app.py â€” Qiyas Bot (Webhook/PTB v21) â€” Ø¨Ø¯ÙˆÙ† Ù…Ù„ÙØ§Øª data
# -------------------------------------------------------
import os, logging, random, re, asyncio
from typing import List, Dict, Any, Optional, Tuple

from telegram import (
    Update, KeyboardButton, ReplyKeyboardMarkup,
    InlineKeyboardButton, InlineKeyboardMarkup
)
from telegram.constants import ChatAction
from telegram.ext import (
    Application, CommandHandler, MessageHandler,
    CallbackQueryHandler, ContextTypes, filters
)

# ================= Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© =================
BOT_TOKEN   = os.environ.get("TELEGRAM_BOT_TOKEN")
WEBHOOK_URL = (os.environ.get("WEBHOOK_URL") or "").rstrip("/")
PORT        = int(os.environ.get("PORT", "10000"))
AI_API_KEY  = os.environ.get("AI_API_KEY")
AI_MODEL    = os.environ.get("AI_MODEL", "gpt-4o-mini")

if not BOT_TOKEN:
    raise RuntimeError("TELEGRAM_BOT_TOKEN Ù…ÙÙ‚ÙˆØ¯")
if not WEBHOOK_URL:
    raise RuntimeError("WEBHOOK_URL Ù…ÙÙ‚ÙˆØ¯ (Ù…Ø«Ø§Ù„: https://your-app.onrender.com)")

# ===== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„) =====
AI_MAX_TOKENS          = int(os.environ.get("AI_MAX_TOKENS", "650"))
AI_TEMPERATURE_DEFAULT = float(os.environ.get("AI_TEMPERATURE", "0.4"))
AI_STYLE_DEFAULT       = os.environ.get("AI_STYLE", "concise")  # concise | detailed

def get_ai_prefs(context):
    prefs = context.user_data.setdefault("ai_prefs", {})
    if "model" not in prefs:
        prefs["model"] = os.environ.get("AI_MODEL", AI_MODEL)
    if "temperature" not in prefs:
        prefs["temperature"] = AI_TEMPERATURE_DEFAULT
    if "style" not in prefs:
        prefs["style"] = AI_STYLE_DEFAULT
    return prefs

def ai_system_prompt(style:str, ei_enabled:bool) -> str:
    tone = "Ù„Ø·ÙŠÙ ÙˆÙ…Ø·Ù…Ø¦Ù†" if ei_enabled else "Ø­ÙŠØ§Ø¯ÙŠ ÙˆÙ…Ø¨Ø§Ø´Ø±"
    depth = "Ù†Ù‚Ø§Ø· Ù…Ø®ØªØµØ±Ø© Ù…Ø¹ Ø®Ø·ÙˆØ§Øª Ù…Ø±Ù‚Ù…Ø©" if style=="concise" else "ØªÙØµÙŠÙ„ ÙˆØ§Ø¶Ø­ Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© Ù‚ØµÙŠØ±Ø© ÙˆØ®Ø·ÙˆØ§Øª Ø¯Ù‚ÙŠÙ‚Ø©"
    encouragement = (
        "Ø§Ø®ØªÙ… Ø¨Ø¬Ù…Ù„Ø© ØªØ´Ø¬ÙŠØ¹ÙŠØ© Ù‚ØµÙŠØ±Ø© ØªØ¶ÙŠÙ Ø¯Ø§ÙØ¹ÙŠØ© Ù„Ù„Ø·Ø§Ù„Ø¨."
        if ei_enabled else
        "Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ø¥ÙŠØ¬Ø§Ø² Ø§Ù„Ù…Ù‡Ù†ÙŠ Ø¯ÙˆÙ† ØªØ´Ø¬ÙŠØ¹ Ø²Ø§Ø¦Ø¯."
    )
    return (
        "Ø£Ù†Øª Ù…Ø¯Ø±Ù‘Ø³ Ù‚Ø¯Ø±Ø§Øª (Ù‚ÙŠØ§Ø³) Ø®Ø¨ÙŠØ± Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. "
        f"Ø§ÙƒØªØ¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ {tone}. Ù‚Ø¯Ù‘Ù… {depth}. "
        "Ù‚Ø³Ù‘Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¥Ù„Ù‰ ÙÙ‚Ø±Ø§Øª Ù…Ù†Ø¸Ù…Ø© Ø¨Ø¹Ù†Ø§ÙˆÙŠÙ† Ù‚ØµÙŠØ±Ø© ÙˆÙ†Ù‚Ø§Ø·. "
        "Ø§Ø±Ø¨Ø· Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¨Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù‚Ø¯Ø±Ø§Øª (ÙƒÙ…ÙŠ/Ù„ÙØ¸ÙŠ) Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©. "
        "ØªØ¬Ù†Ù‘Ø¨ Ø§Ù„Ø­Ø´ÙˆØŒ ÙˆØ§Ø°ÙƒØ± Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¨Ø§Ù‚ØªØ¶Ø§Ø¨. "
        f"{encouragement}"
    )

# ================= Ù„ÙˆÙ‚ =================
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s | %(levelname)s | %(name)s | %(message)s"
)
logging.getLogger("httpx").setLevel(logging.WARNING)
log = logging.getLogger("qiyas-bot")

# ======================================================
#                 Ø°ÙƒØ§Ø¡ Ø¹Ø§Ø·ÙÙŠ (Ù…Ø´Ø¬Ù‘Ø¹)
# ======================================================
EI_DEFAULT = True  # Ù…ÙØ¹Ù‘Ù„ Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹

def get_ei(context):
    return context.user_data.get("ei", EI_DEFAULT)

def set_ei(context, value: bool):
    context.user_data["ei"] = bool(value)

def ei_msg_correct(streak: int) -> str:
    msgs = [
        "ğŸ‘ Ù…Ù…ØªØ§Ø²! Ø«Ø¨Ù‘Øª Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙˆÙ‰.",
        "ğŸ”¥ Ø£Ø¯Ø§Ø¡ Ø¬Ù…ÙŠÙ„! Ø§Ø³ØªÙ…Ø±.",
        "âœ… Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙˆÙÙ‚Ø© â€” ÙƒÙÙˆ.",
        "ğŸŒŸ Ø£Ø­Ø³Ù†Øª! ØªØ±ÙƒÙŠØ²Ùƒ ÙˆØ§Ø¶Ø­."
    ]
    bonus = f"\nØ³Ù„Ø³Ù„Ø© ØµØ­ÙŠØ­Ø© Ù…ØªØªØ§Ù„ÙŠØ©: {streak} âœ”ï¸" if streak >= 3 else ""
    return random.choice(msgs) + bonus

def ei_msg_wrong(explain: Optional[str]) -> str:
    soft = [
        "ÙˆÙ„Ø§ ÙŠÙ‡Ù…Ù‘ÙƒØŒ Ø¬Ø±Ù‘Ø¨ Ø§Ù„Ù„ÙŠ Ø¨Ø¹Ø¯Ù‡ Ø¨Ù‡Ø¯ÙˆØ¡.",
        "ğŸ‘ Ø®Ø°Ù‡Ø§ Ø®Ø·ÙˆØ© Ø®Ø·ÙˆØ©ØŒ ØªØ±ÙƒÙŠØ²Ùƒ Ø£Ù‡Ù….",
        "ğŸ’¡ Ø±Ø§Ø¬Ø¹ Ø§Ù„ÙÙƒØ±Ø© Ø¨Ù‡Ø¯ÙˆØ¡ ÙˆØ³ØªØªØ¶Ø­."
    ]
    tip = f"\nØ§Ù„Ø´Ø±Ø­: {explain}" if explain else ""
    return random.choice(soft) + tip

# ======================================================
#                 Ù…ÙˆÙ„Ù‘ÙØ¯Ø§Øª Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
# ======================================================
def _choice4(correct: int | str, near: List[int | str]) -> Tuple[List[str], int]:
    """ÙŠØ±Ø¬Ø¹ 4 Ø®ÙŠØ§Ø±Ø§Øª Ù…Ø¹ ÙÙ‡Ø±Ø³ Ø§Ù„ØµØ­ÙŠØ­ØŒ Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø¯Ø§Ø¦Ù…Ø§Ù‹."""
    opts: List[str] = []
    seen = set()
    def push(x):
        sx = str(x)
        if sx not in seen and len(opts) < 4:
            opts.append(sx); seen.add(sx)

    push(correct)
    for x in near: push(x)
    while len(opts) < 4:
        v = random.randint(-50, 200)
        if str(v) not in seen: push(v)
    random.shuffle(opts)
    return opts, opts.index(str(correct))

# ---- ÙƒÙ…ÙŠ ----
def gen_quant() -> Dict[str, Any]:
    t = random.choice(["arith", "linear", "percent", "pow", "mix"])
    if t == "arith":
        a, b = random.randint(-20, 90), random.randint(-20, 90)
        op = random.choice(["+", "-", "Ã—", "Ã·"])
        if op == "+":
            val = a + b
            opts, ans = _choice4(val, [val+random.choice([-3,-2,-1,1,2,3]), val+10, val-10])
            q = f"Ø§Ø­Ø³Ø¨: {a} + {b} = ØŸ"
        elif op == "-":
            val = a - b
            opts, ans = _choice4(val, [val+random.choice([-3,-1,1,3]), val+7, val-7])
            q = f"Ø§Ø­Ø³Ø¨: {a} - {b} = ØŸ"
        elif op == "Ã—":
            a, b = random.randint(2, 20), random.randint(2, 15)
            val = a * b
            opts, ans = _choice4(val, [val+a, val-b, val+10])
            q = f"Ø§Ø­Ø³Ø¨: {a} Ã— {b} = ØŸ"
        else:  # Ã·
            b = random.randint(2, 12)
            val = random.randint(2, 12)
            a = b * val
            opts, ans = _choice4(val, [val+1, val-1, val+2])
            q = f"Ø§Ø­Ø³Ø¨: {a} Ã· {b} = ØŸ"
        return {"question": q, "options": opts, "answer_index": ans,
                "explain": "Ø¹Ù…Ù„ÙŠØ§Øª Ø­Ø³Ø§Ø¨ÙŠØ© Ø£Ø³Ø§Ø³ÙŠØ©."}

    if t == "linear":
        a = random.randint(2, 9)
        x = random.randint(-10, 12)
        b = random.randint(-10, 12)
        c = a*x + b
        q = f"Ø¥Ø°Ø§ ÙƒØ§Ù† {a}Ø³ + {b} = {c}ØŒ ÙÙ…Ø§ Ù‚ÙŠÙ…Ø© Ø³ØŸ"
        opts, ans = _choice4(x, [x+1, x-1, x+2])
        return {"question": q, "options": opts, "answer_index": ans,
                "explain": f"Ø³ = ( {c} - {b} ) Ã· {a} = {x}"}

    if t == "percent":
        y = random.randint(20, 200)
        x = random.choice([5,10,12,15,20,25,30,40,50])
        val = round(y * x / 100)
        q = f"Ù…Ø§ {x}% Ù…Ù† {y} ØŸ"
        opts, ans = _choice4(val, [val+5, val-5, val+10])
        return {"question": q, "options": opts, "answer_index": ans,
                "explain": f"{x}% Ã— {y} = {y*x/100:g}"}

    if t == "pow":
        base = random.randint(2, 15)
        exp  = random.choice([2, 3])
        val  = base ** exp
        q = f"Ù‚ÙŠÙ…Ø© {base}^{exp} = ØŸ"
        near = [val+base, val-base, val+2]
        opts, ans = _choice4(val, near)
        return {"question": q, "options": opts, "answer_index": ans,
                "explain": f"{base}^{exp} = {val}"}

    # mix: Ù…Ø³Ø§ÙØ© = Ø³Ø±Ø¹Ø© Ã— Ø²Ù…Ù†
    v = random.randint(30, 120)
    t = random.randint(1, 6)
    d = v * t
    q = f"Ø³ÙŠØ§Ø±Ø© Ø³Ø±Ø¹ØªÙ‡Ø§ {v} ÙƒÙ…/Ø³ØŒ Ø³Ø§Ø±Øª {t} Ø³Ø§Ø¹Ø§Øª. Ù…Ø§ Ø§Ù„Ù…Ø³Ø§ÙØ©ØŸ"
    opts, ans = _choice4(d, [d-10, d+10, d+v])
    return {"question": q, "options": opts, "answer_index": ans,
            "explain": "Ø§Ù„Ù…Ø³Ø§ÙØ© = Ø§Ù„Ø³Ø±Ø¹Ø© Ã— Ø§Ù„Ø²Ù…Ù†."}

# ---- Ù„ÙØ¸ÙŠ ----
SYN = [
    ("ÙŠØ¬Ø§Ø¨Ù‡","ÙŠÙˆØ§Ø¬Ù‡"), ("Ø¬Ù„Ù‘ÙŠ","ÙˆØ§Ø¶Ø­"), ("ÙŠÙ†Ø£Ù‰","ÙŠØ¨ØªØ¹Ø¯"),
    ("ÙŠØ¨ØªÙƒØ±","ÙŠØ¨Ø¯Ø¹"), ("Ù…Ø­Ù†Ø©","Ø§Ø¨ØªÙ„Ø§Ø¡"), ("Ø³Ø§Ø·Ø¹","Ù„Ø§Ù…Ø¹"),
]
ANT = [
    ("Ù…Ø¤Ù‚Ù‘Øª","Ø¯Ø§Ø¦Ù…"), ("Ù‚ÙˆÙŠ","Ø¶Ø¹ÙŠÙ"), ("ÙˆØ¶ÙˆØ­","ØºÙ…ÙˆØ¶"),
    ("Ø³Ù‡Ù„","ØµØ¹Ø¨"), ("Ù‚Ø¯ÙŠÙ…","Ø­Ø¯ÙŠØ«"), ("Ù‚Ø±ÙŠØ¨","Ø¨Ø¹ÙŠØ¯"),
]
COMP_SENT = [
    ("Ø§Ù„Ø·Ø§Ù„Ø¨ ____ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ.", "ØªÙÙˆÙ‚", ["ØªÙÙˆÙ‘Ù‚","ØªØ£Ø®Ù‘Ø±","ØªÙ‡Ø§ÙˆÙ†","Ø§Ù†Ø³Ø­Ø¨"]),
    ("ÙƒØ§Ù† Ø§Ù„Ù‚Ø±Ø§Ø± ____ Ø¨Ø¹Ø¯ Ø¯Ø±Ø§Ø³Ø© Ù…Ø³ØªÙÙŠØ¶Ø©.", "ØµØ§Ø¦Ø¨",  ["ØµØ§Ø¦Ø¨","Ø¹Ø´ÙˆØ§Ø¦ÙŠ","Ù…ÙÙ„ØªØ¨Ø³","Ù…ØªØ³Ø±Ù‘Ø¹"]),
    ("ÙŠØ¬Ø¨ _____ Ø§Ù„ÙˆÙ‚Øª Ù„ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù.", "Ø§Ø³ØªØ«Ù…Ø§Ø±",["Ø¥Ù‡Ø¯Ø§Ø±","ØªØ¶ÙŠÙŠØ¹","Ø§Ø³ØªØ«Ù…Ø§Ø±","ØªØ¬Ù…ÙŠØ¯"]),
]
def gen_verbal() -> Dict[str, Any]:
    kind = random.choice(["syn","ant","analogy","cloze"])
    if kind == "syn":
        a,b = random.choice(SYN)
        wrongs = [w for _,w in SYN if w!=b][:6] + [x for _,x in ANT][:6]
        random.shuffle(wrongs)
        opts = [b] + wrongs[:3]
        random.shuffle(opts)
        return {"question": f"Ù…Ø±Ø§Ø¯Ù Â«{a}Â» Ù‡Ùˆ:", "options": opts,
                "answer_index": opts.index(b), "explain": f"Ù…Ø±Ø§Ø¯Ù Â«{a}Â» = Â«{b}Â»."}
    if kind == "ant":
        a,b = random.choice(ANT)
        wrongs = [w for _,w in ANT if w!=b][:6] + [x for _,x in SYN][:6]
        random.shuffle(wrongs)
        opts = [b] + wrongs[:3]
        random.shuffle(opts)
        return {"question": f"Ø¶Ø¯Ù‘ Â«{a}Â» Ù‡Ùˆ:", "options": opts,
                "answer_index": opts.index(b), "explain": f"Ø¶Ø¯Ù‘ Â«{a}Â» = Â«{b}Â»."}
    if kind == "analogy":
        if random.random()<0.5:
            a,b = random.choice(SYN); c,d = random.choice(SYN)
            q = f"{a} : {b} :: {c} : ØŸ"; target = d
            pool = [d] + [x for _,x in SYN if x!=d][:3]
        else:
            a,b = random.choice(ANT); c,d = random.choice(ANT)
            q = f"{a} : {b} :: {c} : ØŸ"; target = d
            pool = [d] + [x for _,x in ANT if x!=d][:3]
        random.shuffle(pool)
        return {"question": q, "options": pool,
                "answer_index": pool.index(target),
                "explain": "Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ù†ÙØ³Ù‡Ø§ ØªÙØ­Ø§ÙÙØ¸ Ø¹Ù„ÙŠÙ‡Ø§ ÙŠÙ…ÙŠÙ† Ø§Ù„ØªØ´Ø¨ÙŠÙ‡."}
    s, correct, opts_full = random.choice(COMP_SENT)
    opts = opts_full[:]; random.shuffle(opts)
    return {"question": s, "options": opts,
            "answer_index": opts.index(correct),
            "explain": f"Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ø£Ù†Ø³Ø¨: Â«{correct}Â»."}

# ---- Ø°ÙƒØ§Ø¡ ----
AR_LETTERS = list("Ø§Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠ")  # Ø­Ø±ÙˆÙ Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¨Ø³Ù‘Ø·Ø©

def gen_iq() -> Dict[str, Any]:
    k = random.choice(["arith_seq","geom_seq","alt_seq","letter_seq"])
    if k == "arith_seq":
        a = random.randint(1,15); d = random.randint(2,9); n = [a+i*d for i in range(5)]
        ans = n[-1] + d
        opts, idx = _choice4(ans, [ans+d, ans-d, ans+2])
        return {"question": f"Ø£ÙƒÙ…Ù„ Ø§Ù„Ù…ØªØªØ§Ù„ÙŠØ©: {', '.join(map(str,n))}, ØŸ",
                "options": opts, "answer_index": idx, "explain": f"ÙØ±Ù‚ Ø«Ø§Ø¨Øª = {d}"}
    if k == "geom_seq":
        a = random.randint(1,6); r = random.choice([2,3,4]); n = [a*(r**i) for i in range(4)]
        ans = n[-1]*r
        opts, idx = _choice4(ans, [ans*r, ans//r if ans%r==0 else ans-1, ans+r])
        return {"question": f"Ø£ÙƒÙ…Ù„: {', '.join(map(str,n))}, ØŸ",
                "options": opts, "answer_index": idx, "explain": f"Ù…ØªØ¶Ø§Ø¹Ù Ø¨Ù†Ø³Ø¨Ø© {r}"}
    if k == "alt_seq":
        a = random.randint(5,20); d1 = random.randint(2,6); d2 = random.randint(7,12)
        seq = [a, a+d1, a+d1+d2, a+2*d1+d2, a+2*d1+2*d2]
        ans = a+3*d1+2*d2
        opts, idx = _choice4(ans, [ans+d1, ans+d2, ans-1])
        return {"question": f"Ù†Ù…Ø· Ù…ØªÙ†Ø§ÙˆØ¨ (+{d1}, +{d2}): {', '.join(map(str,seq))}, ØŸ",
                "options": opts, "answer_index": idx, "explain": "ÙŠØ²ÙŠØ¯ Ù…Ø±Ù‘Ø© d1 Ø«Ù… d2 Ø¨Ø§Ù„ØªÙ†Ø§ÙˆØ¨."}

    # letter_seq â€” Ø¥ØµÙ„Ø§Ø­ IndexError: Ø§Ø®ØªÙŠØ§Ø± start Ø¢Ù…Ù† Ø­Ø³Ø¨ step
    step = random.randint(1,3)
    max_start = len(AR_LETTERS) - 1 - 5*step
    if max_start < 0:
        # Ø§Ø­ØªÙŠØ§Ø· Ù†Ø¸Ø±ÙŠ Ù„Ùˆ ØªÙ‚Ù„ØµØª Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
        step = 1
        max_start = len(AR_LETTERS) - 6
    start = random.randint(0, max_start)
    seq = [AR_LETTERS[start + i*step] for i in range(5)]
    nxt_index = start + 5*step
    nxt = AR_LETTERS[nxt_index]
    # Ø®ÙŠØ§Ø±Ø§Øª Ø®Ø§Ø·Ø¦Ø© Ù…Ù…ÙŠØ²Ø© (Ù†Ø®ØªØ§Ø± 3 ÙÙ‡Ø§Ø±Ø³ Ù…Ø®ØªÙ„ÙØ© ØºÙŠØ± Ø§Ù„ØµØ­ÙŠØ­Ø©)
    candidates = [i for i in range(len(AR_LETTERS)) if i != nxt_index]
    wrong_idx = random.sample(candidates, 3)
    opts = [nxt] + [AR_LETTERS[i] for i in wrong_idx]
    random.shuffle(opts)
    return {"question": f"Ø£ÙƒÙ…Ù„: {'ØŒ '.join(seq)}, ØŸ",
            "options": opts, "answer_index": opts.index(nxt),
            "explain": f"Ø²ÙŠØ§Ø¯Ø© Ø«Ø§Ø¨ØªØ© Ø¨Ø§Ù„Ø­Ø±ÙˆÙ Ø¨Ù…Ù‚Ø¯Ø§Ø± {step}."}

# ======================================================
#                    Ù…Ø­Ø±Ù‘Ùƒ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
# ======================================================
class QuizSession:
    def __init__(self, generator, limit:int):
        self.gen = generator
        self.total = limit
        self.idx = 0
        self.correct = 0
        self.items: List[Dict[str,Any]] = []

    def _ensure(self):
        while len(self.items) <= self.idx and len(self.items) < self.total:
            self.items.append(self.gen())

    def current(self) -> Optional[Dict[str,Any]]:
        self._ensure()
        return self.items[self.idx] if self.idx < self.total else None

    def check(self, choice:int) -> Dict[str,Any]:
        q = self.current()
        if not q: return {"done": True}
        ok = (choice == q["answer_index"])
        if ok: self.correct += 1
        self.idx += 1
        return {"ok": ok, "answer_index": q["answer_index"], "explain": q.get("explain")}

def fmt_progress(i:int, total:int) -> str:
    blocks = 10
    fill = int((i/total)*blocks)
    return "â– "*fill + "â–¡"*(blocks-fill) + f" {i}/{total}"

def q_text(q:Dict[str,Any], idx:int, total:int, label:str) -> Tuple[str, InlineKeyboardMarkup]:
    letters = ["Ø£","Ø¨","Ø¬","Ø¯","Ù‡Ù€","Ùˆ","Ø²","Ø­"]
    opts = q["options"]
    kb = [[InlineKeyboardButton(f"{letters[i]}) {opts[i]}", callback_data=f"ans|{i}")]
          for i in range(len(opts))]
    text = f"ğŸ§  {label}\nØ§Ù„Ø³Ø¤Ø§Ù„ {idx+1} Ù…Ù† {total}\n{fmt_progress(idx,total)}\n\n{q['question']}"
    return text, InlineKeyboardMarkup(kb)

def session_get(context: ContextTypes.DEFAULT_TYPE, cat:str) -> QuizSession:
    store = context.user_data.setdefault("sessions", {})
    s = store.get(cat)
    if s and isinstance(s, QuizSession):
        return s
    limit = 500 if cat in ("quant","verbal") else 300
    gen = gen_quant if cat=="quant" else gen_verbal if cat=="verbal" else gen_iq
    s = QuizSession(gen, limit)
    store[cat] = s
    return s

async def send_next(update:Update, context:ContextTypes.DEFAULT_TYPE, cat:str, label:str):
    s = session_get(context, cat)
    q = s.current()
    if not q:
        await update.effective_message.reply_text(
            f"Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± âœ…\nØ§Ù„Ù†ØªÙŠØ¬Ø©: {s.correct}/{s.total}",
            reply_markup=ReplyKeyboardMarkup(MAIN_BTNS, resize_keyboard=True)
        )
        context.user_data["sessions"].pop(cat, None)
        return
    txt, kb = q_text(q, s.idx, s.total, label)
    context.user_data["last_cat"] = cat  # Ù„ØªÙ…ÙŠÙŠØ² Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø£Ø²Ø±Ø§Ø±
    await update.effective_message.reply_text(txt, reply_markup=kb)

# ======================================================
#                     ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
# ======================================================
MAIN_BTNS = [
    [KeyboardButton("Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¶Ø±Ø¨")],
    [KeyboardButton("Ù‚Ø¯Ø±Ø§Øª ÙƒÙ…ÙŠ (500 Ø³Ø¤Ø§Ù„)")],
    [KeyboardButton("Ù‚Ø¯Ø±Ø§Øª Ù„ÙØ¸ÙŠ (500 Ø³Ø¤Ø§Ù„)")],
    [KeyboardButton("Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ (300 Ø³Ø¤Ø§Ù„)")],
    [KeyboardButton("Ø§Ø³Ø£Ù„ Ù‚ÙŠØ§Ø³ (Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ)")],
]
MAIN_KB = ReplyKeyboardMarkup(MAIN_BTNS, resize_keyboard=True)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Ù…Ø±Ø­Ø¨Ù‹Ø§! Ø§Ø®ØªØ± Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ğŸ‘‡", reply_markup=MAIN_KB)

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "/start Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©\n/quant ÙƒÙ…ÙŠ\n/verbal Ù„ÙØ¸ÙŠ\n/iq Ø°ÙƒØ§Ø¡\n/table Ø¬Ø¯ÙˆÙ„ Ø¶Ø±Ø¨\n"
        "/ask_ai Ø³Ø¤Ø§Ù„Ùƒ\n/ai_prefs Ø¹Ø±Ø¶ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡\n/ai_model ØªØºÙŠÙŠØ± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„\n"
        "/ai_temp ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø±Ø§Ø±Ø©\n/ai_style ØªØºÙŠÙŠØ± Ø§Ù„Ø£Ø³Ù„ÙˆØ¨\n/ei_on ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¹Ø§Ø·Ù\n/ei_off Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ¹Ø§Ø·Ù"
    )

# ====== Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¶Ø±Ø¨ ======
def parse_mul_expr(s: str) -> Tuple[bool, int, int]:
    s = s.replace("Ã—","x").replace("X","x").replace("*","x")
    m = re.fullmatch(r"\s*(-?\d+)\s*x\s*(-?\d+)\s*", s)
    if not m:
        return False, 0, 0
    return True, int(m.group(1)), int(m.group(2))

def mult_table(n:int, upto:int=12) -> str:
    rows = [f"ğŸ“ Ø¬Ø¯ÙˆÙ„ Ø¶Ø±Ø¨ {n}:"]
    for i in range(1,upto+1):
        rows.append(f"{n} Ã— {i} = {n*i}")
    return "\n".join(rows)

def clean_number_only(text: str) -> Optional[int]:
    t = text.strip()
    m = re.fullmatch(r"(-?\d+)", t)
    return int(m.group(1)) if m else None

# ====== Ù…ÙˆØ¬Ù‘Ù‡ Ø§Ù„Ù†Øµ ======
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    t = (update.message.text or "").strip()

    if "Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¶Ø±Ø¨" in t:
        await update.message.reply_text("Ø£Ø±Ø³Ù„ Ø±Ù‚Ù…Ù‹Ø§ (Ù…Ø«Ù„ 7) Ù„Ø¬Ø¯ÙˆÙ„ ÙƒØ§Ù…Ù„ØŒ Ø£Ùˆ ØµÙŠØºØ© (7Ã—7 / 7x7) Ù„Ù†Ø§ØªØ¬ ÙÙˆØ±ÙŠ."); return
    if "ÙƒÙ…ÙŠ" in t:
        context.user_data.get("sessions", {}).pop("quant", None)
        context.user_data["streak"] = 0
        await update.message.reply_text("Ø³ÙŠØ¨Ø¯Ø£ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒÙ…ÙŠ (Ø­ØªÙ‰ Ù¥Ù Ù ). Ø¨Ø§Ù„ØªÙˆÙÙŠÙ‚! ğŸ’ª")
        await send_next(update, context, "quant", "Ù‚Ø¯Ø±Ø§Øª ÙƒÙ…ÙŠ"); return
    if "Ù„ÙØ¸ÙŠ" in t:
        context.user_data.get("sessions", {}).pop("verbal", None)
        context.user_data["streak"] = 0
        await update.message.reply_text("Ø³ÙŠØ¨Ø¯Ø£ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù„ÙØ¸ÙŠ (Ø­ØªÙ‰ Ù¥Ù Ù ). Ø±ÙƒÙ‘Ø² ğŸ‘€")
        await send_next(update, context, "verbal", "Ù‚Ø¯Ø±Ø§Øª Ù„ÙØ¸ÙŠ"); return
    if "Ø§Ù„Ø°ÙƒØ§Ø¡" in t:
        context.user_data.get("sessions", {}).pop("iq", None)
        context.user_data["streak"] = 0
        await update.message.reply_text("Ø³ÙŠØ¨Ø¯Ø£ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø°ÙƒØ§Ø¡ (Ø­ØªÙ‰ Ù£Ù Ù ).")
        await send_next(update, context, "iq", "Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø°ÙƒØ§Ø¡"); return
    if "Ø§Ø³Ø£Ù„ Ù‚ÙŠØ§Ø³" in t:
        await update.message.reply_text("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø¨Ø¹Ø¯ Ø§Ù„Ø£Ù…Ø±:\n/ask_ai ÙƒÙŠÙ Ø£Ø³ØªØ¹Ø¯ Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù‚Ø¯Ø±Ø§ØªØŸ"); return

    # ØªØ¹Ø¨ÙŠØ± Ø¶Ø±Ø¨ Ù…Ø¨Ø§Ø´Ø±
    ok, a, b = parse_mul_expr(t)
    if ok:
        await update.message.reply_text(f"{a} Ã— {b} = {a*b}"); return

    # Ø±Ù‚Ù… ÙÙ‚Ø· â†’ Ø¬Ø¯ÙˆÙ„ ÙƒØ§Ù…Ù„
    n = clean_number_only(t)
    if n is not None:
        await update.message.reply_text(mult_table(n)); return

    await update.message.reply_text("Ø§Ø®ØªØ± Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ùˆ /help", reply_markup=MAIN_KB)

# ====== Ø£ÙˆØ§Ù…Ø± Ù…Ø®ØªØµØ±Ø© ======
async def cmd_quant(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.get("sessions", {}).pop("quant", None)
    context.user_data["streak"] = 0
    await send_next(update, context, "quant", "Ù‚Ø¯Ø±Ø§Øª ÙƒÙ…ÙŠ")

async def cmd_verbal(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.get("sessions", {}).pop("verbal", None)
    context.user_data["streak"] = 0
    await send_next(update, context, "verbal", "Ù‚Ø¯Ø±Ø§Øª Ù„ÙØ¸ÙŠ")

async def cmd_iq(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.get("sessions", {}).pop("iq", None)
    context.user_data["streak"] = 0
    await send_next(update, context, "iq", "Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø°ÙƒØ§Ø¡")

async def cmd_ei_on(update: Update, context: ContextTypes.DEFAULT_TYPE):
    set_ei(context, True)
    await update.message.reply_text("ØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ âœ…")

async def cmd_ei_off(update: Update, context: ContextTypes.DEFAULT_TYPE):
    set_ei(context, False)
    await update.message.reply_text("ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ â›”ï¸")

# ====== Ø§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„Ø£Ø²Ø±Ø§Ø± ======
async def cb_answer(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    m = re.fullmatch(r"ans\|(\d+)", (query.data or ""))
    if not m: return
    choice = int(m.group(1))

    cat = context.user_data.get("last_cat")
    if cat not in ("quant","verbal","iq"):
        await query.edit_message_text("Ø§Ù†ØªÙ‡Øª Ø§Ù„Ø¬Ù„Ø³Ø©. Ø§Ø¨Ø¯Ø£ Ù…Ù† Ø¬Ø¯ÙŠØ¯ /start"); return

    s = session_get(context, cat)
    res = s.check(choice)
    right_letter = ["Ø£","Ø¨","Ø¬","Ø¯","Ù‡Ù€","Ùˆ","Ø²","Ø­"][res["answer_index"]]
    streak = context.user_data.get("streak", 0)

    if res["ok"]:
        streak += 1
        context.user_data["streak"] = streak
        msg = f"âœ”ï¸ ØµØ­ÙŠØ­! ({s.correct}/{s.total})"
        if get_ei(context):
            msg += "\n" + ei_msg_correct(streak)
    else:
        context.user_data["streak"] = 0
        msg = f"âŒ Ø®Ø·Ø£.\nØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©: {right_letter}"
        if get_ei(context):
            msg += "\n" + ei_msg_wrong(res.get("explain"))

    await query.edit_message_text(msg)
    label = "Ù‚Ø¯Ø±Ø§Øª ÙƒÙ…ÙŠ" if cat=="quant" else "Ù‚Ø¯Ø±Ø§Øª Ù„ÙØ¸ÙŠ" if cat=="verbal" else "Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø°ÙƒØ§Ø¡"
    await send_next(update, context, cat, label)

# ====== Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ======
async def ask_ai(update: Update, context: ContextTypes.DEFAULT_TYPE):
    txt = (update.message.text or "")
    q = None
    if txt.startswith("/ask_ai") and " " in txt:
        q = txt.split(" ", 1)[1].strip()
    elif update.message and update.message.reply_to_message:
        q = (update.message.reply_to_message.text or "").strip()

    if not q:
        await update.message.reply_text(
            "Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø¨Ø¹Ø¯ Ø§Ù„Ø£Ù…Ø±:\n"
            "/ask_ai ÙƒÙŠÙ Ø£Ø°Ø§ÙƒØ± Ø§Ù„Ù‚Ø¯Ø±Ø§ØªØŸ\n"
            "Ø£Ùˆ Ø±Ø¯Ù‘ Ø¨Ø§Ù„Ø£Ù…Ø± Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„Ø© ØªØ­ØªÙˆÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„."
        )
        return
    if not AI_API_KEY:
        await update.message.reply_text("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø¶Ø¨Ø· AI_API_KEY ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù… (Render).")
        return

    prefs = get_ai_prefs(context)
    ei_enabled = get_ei(context)
    system_msg = ai_system_prompt(prefs["style"], ei_enabled)

    try:
        await update.effective_chat.send_action(ChatAction.TYPING)
        from openai import OpenAI
        client = OpenAI(api_key=AI_API_KEY)

        def _call():
            return client.chat.completions.create(
                model=prefs["model"],
                temperature=prefs["temperature"],
                max_tokens=AI_MAX_TOKENS,
                messages=[
                    {"role":"system","content": system_msg},
                    {"role":"user","content": q}
                ],
            )

        resp = await asyncio.wait_for(asyncio.to_thread(_call), timeout=25)
        answer = (resp.choices[0].message.content or "").strip() or "Ù„Ù… Ø£Ø³ØªØ·Ø¹ ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø¢Ù†."
        for i in range(0, len(answer), 4000):
            await update.message.reply_text(answer[i:i+4000])

    except asyncio.TimeoutError:
        await update.message.reply_text("â±ï¸ Ø§Ù†ØªÙ‡Øª Ø§Ù„Ù…Ù‡Ù„Ø©. Ø¬Ø±Ù‘Ø¨ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø£Ù‚ØµØ± Ø£Ùˆ Ø£Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©.")
    except Exception as e:
        msg = str(e)
        if "401" in msg or "Unauthorized" in msg or "Incorrect API key" in msg:
            hint = "ØªØ­Ù‚Ù‘Ù‚ Ù…Ù† AI_API_KEY (ÙŠØ¨Ø¯Ø£ Ø¨Ù€ sk-)."
        elif "model" in msg and ("not found" in msg or "does not exist" in msg):
            hint = f"Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ØºÙŠØ± ØµØ­ÙŠØ­. Ø§Ù„Ø­Ø§Ù„ÙŠ: {prefs['model']}"
        elif "429" in msg or "rate limit" in msg:
            hint = "ØªØ¬Ø§ÙˆØ²Øª Ø­Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…. Ø§Ù†ØªØ¸Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ø«Ù… Ø£Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©."
        else:
            hint = "ØªØ¹Ø°Ù‘Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø¯Ù…Ø©."
        await update.message.reply_text(f"âŒ Ø®Ø·Ø£ ÙÙŠ /ask_ai:\n{msg}\nØ§Ù„Ø§Ù‚ØªØ±Ø§Ø­: {hint}")

# ====== Ø£ÙˆØ§Ù…Ø± ØªØ­ÙƒÙ… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ ======
async def cmd_ai_style(update: Update, context: ContextTypes.DEFAULT_TYPE):
    args = (update.message.text or "").split()
    if len(args) < 2 or args[1] not in ("concise","detailed"):
        await update.message.reply_text("Ø§Ø³ØªØ®Ø¯Ù…: /ai_style concise Ø£Ùˆ /ai_style detailed"); return
    prefs = get_ai_prefs(context)
    prefs["style"] = args[1]
    await update.message.reply_text(f"ØªÙ… Ø¶Ø¨Ø· Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰: {args[1]}")

async def cmd_ai_temp(update: Update, context: ContextTypes.DEFAULT_TYPE):
    args = (update.message.text or "").split()
    if len(args) < 2:
        await update.message.reply_text("Ø§Ø³ØªØ®Ø¯Ù…: /ai_temp 0.2 Ø¥Ù„Ù‰ 1.5"); return
    try:
        t = float(args[1]); 
        if not (0.0 <= t <= 1.5): raise ValueError()
    except:
        await update.message.reply_text("Ù‚ÙŠÙ…Ø© ØºÙŠØ± ØµØ§Ù„Ø­Ø©. Ø§Ø®ØªØ± Ø±Ù‚Ù…Ù‹Ø§ Ø¨ÙŠÙ† 0.0 Ùˆ 1.5"); return
    prefs = get_ai_prefs(context)
    prefs["temperature"] = t
    await update.message.reply_text(f"ØªÙ… Ø¶Ø¨Ø· Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø¹Ù„Ù‰: {t:g}")

async def cmd_ai_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    args = (update.message.text or "").split(maxsplit=1)
    if len(args) < 2:
        await update.message.reply_text("Ø§Ø³ØªØ®Ø¯Ù…: /ai_model Ø§Ø³Ù…_Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Ù…Ø«Ø§Ù„: gpt-4o-mini)"); return
    prefs = get_ai_prefs(context)
    prefs["model"] = args[1].strip()
    await update.message.reply_text(f"ØªÙ… Ø¶Ø¨Ø· Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù„Ù‰: {prefs['model']}")

async def cmd_ai_prefs(update: Update, context: ContextTypes.DEFAULT_TYPE):
    prefs = get_ai_prefs(context)
    await update.message.reply_text(
        "Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø­Ø§Ù„ÙŠØ©:\n"
        f"- Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„: {prefs['model']}\n"
        f"- Ø§Ù„Ø­Ø±Ø§Ø±Ø©: {prefs['temperature']}\n"
        f"- Ø§Ù„Ø£Ø³Ù„ÙˆØ¨: {prefs['style']} (concise|detailed)\n"
        f"- Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ: {'Ù…ÙØ¹Ù‘Ù„' if get_ei(context) else 'Ù…ØªÙˆÙ‚Ù'}\n"
        "ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø¨Ø§Ù„Ø£ÙˆØ§Ù…Ø±: /ai_model /ai_temp /ai_style /ei_on /ei_off"
    )

# ====== Ù…ÙØ¹Ø§Ù„Ø¬ Ø£Ø®Ø·Ø§Ø¡ Ø¹Ø§Ù… ======
async def on_error(update: object, context: ContextTypes.DEFAULT_TYPE):
    log.exception("Exception in handler", exc_info=context.error)
    try:
        if isinstance(update, Update) and update.effective_message:
            await update.effective_message.reply_text("âš ï¸ ØµØ§Ø± Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ù‘Ø¹ ÙˆØªÙ… ØªØ³Ø¬ÙŠÙ„Ù‡. Ø¬Ø±Ù‘Ø¨ Ø§Ù„Ø£Ù…Ø± Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
    except Exception:
        pass

# ================= ØªØ´ØºÙŠÙ„ (Webhook ÙÙ‚Ø·) =================
def build() -> Application:
    app = Application.builder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("quant", cmd_quant))
    app.add_handler(CommandHandler("verbal", cmd_verbal))
    app.add_handler(CommandHandler("iq", cmd_iq))
    app.add_handler(CommandHandler("table", lambda u,c: u.message.reply_text("Ø£Ø±Ø³Ù„ Ø±Ù‚Ù…Ù‹Ø§ (7) Ù„Ø¬Ø¯ÙˆÙ„ØŒ Ø£Ùˆ 7Ã—9 Ù„Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ÙÙˆØ±ÙŠ")))
    app.add_handler(CommandHandler("ei_on", cmd_ei_on))
    app.add_handler(CommandHandler("ei_off", cmd_ei_off))
    app.add_handler(CommandHandler("ask_ai", ask_ai))

    # Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ­ÙƒÙ… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡
    app.add_handler(CommandHandler("ai_style", cmd_ai_style))
    app.add_handler(CommandHandler("ai_temp",  cmd_ai_temp))
    app.add_handler(CommandHandler("ai_model", cmd_ai_model))
    app.add_handler(CommandHandler("ai_prefs", cmd_ai_prefs))

    app.add_handler(CallbackQueryHandler(cb_answer, pattern=r"^ans\|"))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_error_handler(on_error)
    return app

def main():
    app = build()
    log.info("Webhook on %s", WEBHOOK_URL)
    app.run_webhook(
        listen="0.0.0.0", port=PORT,
        url_path=BOT_TOKEN,
        webhook_url=f"{WEBHOOK_URL}/{BOT_TOKEN}",
        drop_pending_updates=True,
    )

if __name__ == "__main__":
    main()
